import requests
import json
import os
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET

# Configuration
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
REPO_OWNER = os.getenv("REPO_OWNER")
REPO_NAME = os.getenv("REPO_NAME")

def fetch_code_scanning_alerts():
    """Fetch high/critical severity alerts from GitHub Code Scanning"""
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Accept": "application/vnd.github.v3+json"
    }
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/code-scanning/alerts"
    alerts = []
    
    try:
        # Fetch the first page of alerts
        while url:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            alerts_page = response.json()
            alerts.extend(alerts_page)

            # Handle pagination (next page)
            if 'link' in response.headers and 'rel="next"' in response.headers['link']:
                url = response.links['next']['url']
            else:
                break

        print(f"Found {len(alerts)} alerts.")
        
        # Filter out relevant alerts with severity 'error' or 'warning' and 'high' security severity level
        valid_alerts = [
            alert for alert in alerts 
            if alert['state'] == 'open' and 
               alert['rule']['severity'] in ['error', 'warning'] and
               alert['rule'].get('security_severity_level', '').lower() == 'high'
        ]
        print(f"Found {len(valid_alerts)} valid alerts.")

        return valid_alerts

    except Exception as e:
        print(f"Error fetching GitHub alerts: {str(e)}")
        return []


def get_cwe_exploitability(cwe_id):
    """Fetch exploit likelihood from CWE API"""
    cwe_number = cwe_id.split('-')[-1].lstrip('0')  # Remove leading zeroes from the CWE ID
    cwe_url = f"https://cwe-api.mitre.org/api/v1/cwe/weakness/{cwe_number}"
    
    try:
        # Fetch the CWE details from the CWE API
        response = requests.get(cwe_url)
        response.raise_for_status()
        cwe_data = response.json()
        
        # Extract the likelihood of exploit only when present
        if 'Weaknesses' in cwe_data and len(cwe_data['Weaknesses']) > 0:
            likelihood = cwe_data['Weaknesses'][0].get('LikelihoodOfExploit', 'Unknown')
            return likelihood
        
        return "Unknown"
    except Exception as e:
        print(f"Error fetching exploitability data for CWE-{cwe_number}: {str(e)}")
        return "Unknown"


def analyze_vulnerabilities():
    """Main analysis function"""
    print("Fetching high/critical severity alerts...")
    alerts = fetch_code_scanning_alerts()
    
    results = []
    for alert in alerts:
        # Extract CWE IDs from tags
        cwes = [tag.split('/')[-1].upper() 
               for tag in alert['rule'].get('tags', []) 
               if tag.startswith('external/cwe/')]
        
        for cwe in cwes:
            exploit_likelihood = get_cwe_exploitability(cwe)
            
            if exploit_likelihood.lower() in ['high', 'very high']:
                results.append({
                    'alert_name': alert['rule']['name'],
                    'severity': alert['rule']['severity'],  # Use 'severity' from the rule object
                    'cwe': cwe,
                    'exploit_likelihood': exploit_likelihood,
                    'html_url': alert['html_url'],
                    'created_at': alert['created_at']
                })
    
    print("\nCritical Vulnerabilities with High Exploit Likelihood:")
    print("="*60)
    for vuln in results:
        print(f"Alert: {vuln['alert_name']}")
        print(f"Severity: {vuln['severity']}")
        print(f"CWE: {vuln['cwe']}")
        print(f"Exploit Likelihood: {vuln['exploit_likelihood']}")
        print(f"URL: {vuln['html_url']}")
        print(f"Created: {vuln['created_at']}")
        print("-"*60)

if __name__ == "__main__":
    analyze_vulnerabilities()
